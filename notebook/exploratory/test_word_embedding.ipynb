{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use torch.Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2223, -2.3308, -0.6108,  0.7259, -0.2903, -0.8751,  1.7559,  1.5828,\n",
      "          0.2943, -0.1676, -0.9944,  1.5499, -1.8404, -1.1475, -1.2277, -1.2573,\n",
      "          1.3946,  0.3825, -0.4465, -0.4496,  0.2936,  0.9580,  0.0199,  0.0070,\n",
      "          0.5718, -1.0833,  0.7940, -1.3834, -0.7509,  2.3869, -0.5971, -0.9588,\n",
      "          1.1152,  0.0605,  0.5032, -0.2663, -1.9301, -1.5963, -0.3757, -1.5852]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Embedding layer with 5 vocab size and 40 vector embeddings.\n",
    "embedding = nn.Embedding(5, 40)\n",
    "# passing the input\n",
    "embed = embedding(torch.LongTensor([1]))\n",
    "# printing the embedding\n",
    "print(embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the dictionary\n",
    "word_to_ix = {'geeks': 0, 'for': 1, 'code': 2}\n",
    "# creating embedding layer -3words in vocab, 5-dimennsional embedding\n",
    "embedding = nn.Embedding(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index of geeks : tensor([0])\n",
      "embeddin of geeks : tensor([[ 1.1538,  0.2501, -0.3989, -0.1271,  0.3281]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# converting the words to indices\n",
    "lookup_tensor = torch.LongTensor([word_to_ix['geeks']])\n",
    "print(f'index of geeks : {lookup_tensor}')\n",
    "# accessing the embedding of the word 'geeks'\n",
    "embed = embedding(lookup_tensor)\n",
    "# printing the embedding\n",
    "print(f'embeddin of geeks : {embed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'this': 2, 'is': 2, 'the': 2, 'second': 1, 'example': 1, 'showing': 1, 'for': 1, 'article': 1, 'at': 1, 'gfg.': 1, 'and': 1, 'doing': 1, 'actually': 1, 'really': 1, 'fun': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# this is going to be the dummy sentence :\n",
    "sentences = 'this is the second example showing for the article at gfg. and doing this is actually really fun'\n",
    "words = sentences.split(' ')\n",
    "\n",
    "# creating the dictionary\n",
    "vocab = Counter(words)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(vocab.get('this'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'the', 'second', 'example', 'showing', 'for', 'article', 'at', 'gfg.', 'and', 'doing', 'actually', 'really', 'fun']\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(vocab, key=vocab.get, reverse=True)\n",
    "vocab_size = len(vocab)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 0,\n",
       " 'is': 1,\n",
       " 'the': 2,\n",
       " 'second': 3,\n",
       " 'example': 4,\n",
       " 'showing': 5,\n",
       " 'for': 6,\n",
       " 'article': 7,\n",
       " 'at': 8,\n",
       " 'gfg.': 9,\n",
       " 'and': 10,\n",
       " 'doing': 11,\n",
       " 'actually': 12,\n",
       " 'really': 13,\n",
       " 'fun': 14}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a word to index dictionary from our Vocab dictionary\n",
    "word2idx = {word: ind for ind, word in enumerate(vocab)}\n",
    "word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 2, 7, 8, 9, 10, 11, 0, 1, 12, 13, 14]\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "encoded_sentences = [word2idx[word] for word in words]\n",
    "print(encoded_sentences)\n",
    "print(len(encoded_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign a value to your embedding_dim\n",
    "e_dim = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.3914,  0.2771, -0.3728, -1.2869,  0.8437],\n",
      "        [-0.5249, -0.2965,  0.6732,  0.6804,  1.6346],\n",
      "        [ 0.1174,  1.5205,  1.1420,  0.3429,  1.0084],\n",
      "        [ 2.3359, -0.1517, -0.0295,  0.5667, -0.1168],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.7529, -0.0876,  1.1717,  0.4178, -0.9127],\n",
      "        [ 0.4264,  0.4380, -1.1234, -1.6403, -1.0220],\n",
      "        [ 0.1174,  1.5205,  1.1420,  0.3429,  1.0084],\n",
      "        [-1.6007,  0.1483, -1.4101,  0.3001, -0.7306],\n",
      "        [-0.6380, -0.1692, -0.6443, -0.1396, -0.2226],\n",
      "        [-0.8895,  0.9895,  1.8986, -0.2961, -0.4691],\n",
      "        [-0.1516,  0.3009, -0.3534, -0.3958, -0.5701],\n",
      "        [ 2.2056, -0.5948, -0.0100,  1.7196, -1.0177],\n",
      "        [ 1.3914,  0.2771, -0.3728, -1.2869,  0.8437],\n",
      "        [-0.5249, -0.2965,  0.6732,  0.6804,  1.6346],\n",
      "        [ 0.6834,  0.9631, -0.5920, -0.5491, -1.0756],\n",
      "        [ 1.3487, -0.6275, -1.9060, -0.0271, -0.6886],\n",
      "        [ 0.2421, -0.8397, -1.2472, -0.1437,  0.0667]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# itnitialize an embedding layer from torch\n",
    "emb = nn.Embedding(vocab_size, e_dim, padding_idx=4)\n",
    "word_vectors = emb(torch.LongTensor(encoded_sentences))\n",
    "print(word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word embeddings before training:\n",
      "word: this, \tindex: 0, \tembedding: [ 1.3913515   0.27706462 -0.37281248 -1.2869236   0.8436893 ]\n",
      "word: is, \tindex: 1, \tembedding: [-0.52494156 -0.2965001   0.67322344  0.6804152   1.6346322 ]\n",
      "word: the, \tindex: 2, \tembedding: [0.11736465 1.5205255  1.1420084  0.34287617 1.0083663 ]\n",
      "word: second, \tindex: 3, \tembedding: [ 2.335879   -0.15165833 -0.02950949  0.5667186  -0.11676569]\n",
      "word: example, \tindex: 4, \tembedding: [0. 0. 0. 0. 0.]\n",
      "word: showing, \tindex: 5, \tembedding: [ 0.75292563 -0.08755481  1.1717112   0.4177512  -0.9127103 ]\n",
      "word: for, \tindex: 6, \tembedding: [ 0.42641672  0.4379722  -1.1233633  -1.6403062  -1.022011  ]\n",
      "word: article, \tindex: 7, \tembedding: [0.11736465 1.5205255  1.1420084  0.34287617 1.0083663 ]\n",
      "word: at, \tindex: 8, \tembedding: [-1.6007452   0.14827983 -1.410069    0.30005357 -0.7306243 ]\n",
      "word: gfg., \tindex: 9, \tembedding: [-0.63801306 -0.16921443 -0.644254   -0.1396184  -0.22259837]\n",
      "word: and, \tindex: 10, \tembedding: [-0.8895002   0.98949236  1.8986195  -0.2961363  -0.46908656]\n",
      "word: doing, \tindex: 11, \tembedding: [-0.15159601  0.3009261  -0.35343355 -0.39577913 -0.57014936]\n",
      "word: actually, \tindex: 12, \tembedding: [ 2.2056425  -0.59483767 -0.00998172  1.7196335  -1.0177252 ]\n",
      "word: really, \tindex: 13, \tembedding: [ 1.3913515   0.27706462 -0.37281248 -1.2869236   0.8436893 ]\n",
      "word: fun, \tindex: 14, \tembedding: [-0.52494156 -0.2965001   0.67322344  0.6804152   1.6346322 ]\n"
     ]
    }
   ],
   "source": [
    "print('The word embeddings before training:')\n",
    "for word, index in word2idx.items():\n",
    "    print(f'word: {word}, \\tindex: {index}, \\tembedding: {word_vectors[index].data.numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`padding_idx` padding idx should denote 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
